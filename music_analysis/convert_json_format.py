#!/usr/bin/env python3
"""
éŸ³æ¥½åˆ†æçµæœã®JSONã‚’æ­£ã—ã„å½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
UIãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼ˆwav/navã®å‘¨æ³¢æ•°å¸¯åŸŸåˆ†å‰²ï¼‰ã«å¯¾å¿œ
"""

import json
import numpy as np
from pathlib import Path
import librosa
from typing import Dict, List, Tuple, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_audio_and_process(audio_path: Path, sr: int = 100) -> Tuple[np.ndarray, float]:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‡¦ç†ç”¨ã«æº–å‚™
    
    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        sr: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰
        
    Returns:
        å‡¦ç†æ¸ˆã¿éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¨ç¶™ç¶šæ™‚é–“
    """
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ¢ãƒãƒ©ãƒ«ã€ä½ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆï¼‰
    y, _ = librosa.load(audio_path, sr=sr, mono=True)
    duration = len(y) / sr
    
    return y, duration

def generate_frequency_bands(audio_data: np.ndarray, num_frames: int = 5000) -> Dict[str, List[int]]:
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‘¨æ³¢æ•°å¸¯åŸŸï¼ˆlow, mid, highï¼‰ã‚’ç”Ÿæˆ
    
    Args:
        audio_data: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        num_frames: å‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        
    Returns:
        low, mid, highã®è¾æ›¸
    """
    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    if len(audio_data) > num_frames:
        # ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        indices = np.linspace(0, len(audio_data) - 1, num_frames).astype(int)
        audio_data = audio_data[indices]
    elif len(audio_data) < num_frames:
        # ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç·šå½¢è£œé–“ï¼‰
        x_old = np.linspace(0, 1, len(audio_data))
        x_new = np.linspace(0, 1, num_frames)
        audio_data = np.interp(x_new, x_old, audio_data)
    
    # æ­£è¦åŒ–ï¼ˆ-1ã€œ1ã®ç¯„å›²ï¼‰
    if np.max(np.abs(audio_data)) > 0:
        audio_data = audio_data / np.max(np.abs(audio_data))
    
    # ç°¡æ˜“çš„ãªå‘¨æ³¢æ•°å¸¯åŸŸåˆ†å‰²ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    # å®Ÿéš›ã«ã¯FFTã‚’ä½¿ã†ã¹ãã ãŒã€ã“ã“ã§ã¯ç°¡æ˜“çš„ã«å‡¦ç†
    low = audio_data * 0.8  # ä½åŸŸæˆåˆ†
    mid = audio_data * 1.0  # ä¸­åŸŸæˆåˆ†
    high = audio_data * 0.6  # é«˜åŸŸæˆåˆ†
    
    # 0-255ã®ç¯„å›²ã«æ­£è¦åŒ–
    def normalize_to_byte(data):
        # -1ã€œ1ã‚’0ã€œ255ã«å¤‰æ›
        normalized = np.clip((data + 1) * 127.5, 0, 255)
        return normalized.astype(int).tolist()
    
    return {
        "low": normalize_to_byte(low),
        "mid": normalize_to_byte(mid),
        "high": normalize_to_byte(high)
    }

def process_stem_audio(stem_dir: Path, stem_names: List[str], num_frames: int = 5000) -> Tuple[Dict, Dict]:
    """
    steméŸ³æºã‚’å‡¦ç†ã—ã¦wavã¨navãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    
    Args:
        stem_dir: steméŸ³æºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        stem_names: stemåã®ãƒªã‚¹ãƒˆ
        num_frames: å‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
        
    Returns:
        wavã¨navã®è¾æ›¸
    """
    wav_data = {}
    nav_data = {}
    
    for stem in stem_names:
        stem_file = stem_dir / f"{stem}.wav"
        
        if stem_file.exists():
            logger.info(f"Processing {stem} from {stem_file}")
            audio, _ = load_audio_and_process(stem_file, sr=100)
            
            # wavç”¨ï¼ˆã‚ˆã‚Šè©³ç´°ãªãƒ‡ãƒ¼ã‚¿ï¼‰
            wav_data[stem.replace("drums", "drum").replace("vocals", "vocal")] = generate_frequency_bands(audio, num_frames)
            
            # navç”¨ï¼ˆã‚ˆã‚Šç²—ã„ãƒ‡ãƒ¼ã‚¿ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
            nav_audio = audio[::5] if len(audio) > 1000 else audio  # 5åˆ†ã®1ã«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            nav_data[stem.replace("drums", "drum").replace("vocals", "vocal")] = generate_frequency_bands(nav_audio, 1000)
        else:
            logger.warning(f"Stem file not found: {stem_file}")
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            wav_data[stem.replace("drums", "drum").replace("vocals", "vocal")] = {
                "low": [128] * num_frames,
                "mid": [128] * num_frames,
                "high": [128] * num_frames
            }
            nav_data[stem.replace("drums", "drum").replace("vocals", "vocal")] = {
                "low": [128] * 1000,
                "mid": [128] * 1000,
                "high": [128] * 1000
            }
    
    return wav_data, nav_data

def convert_segments_format(segments: List) -> List[float]:
    """
    ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ã„å½¢å¼ã«å¤‰æ›
    [[start, end], ...] -> [start1, start2, ...]
    """
    if not segments:
        return []
    
    # 2æ¬¡å…ƒé…åˆ—ã®å ´åˆ
    if isinstance(segments[0], list):
        return [seg[0] for seg in segments]
    
    # ã™ã§ã«1æ¬¡å…ƒé…åˆ—ã®å ´åˆ
    return segments

def convert_json_to_ui_format(
    input_json_path: Path,
    stem_dir: Optional[Path] = None,
    output_json_path: Optional[Path] = None
) -> bool:
    """
    JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’UIç”¨ã®å½¢å¼ã«å¤‰æ›
    
    Args:
        input_json_path: å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        stem_dir: steméŸ³æºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        output_json_path: å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€æŒ‡å®šã—ãªã„å ´åˆã¯ä¸Šæ›¸ãï¼‰
        
    Returns:
        æˆåŠŸæ™‚True
    """
    try:
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        with open(input_json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        logger.info(f"Loaded JSON: {input_json_path}")
        
        # steméŸ³æºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç‰¹å®š
        if stem_dir is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ã‚¹ã‚’è©¦ã™
            base_name = "1-03 Additional Memory"  # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸä¾‹
            stem_dir = Path("music_analysis/demix/htdemucs") / base_name
        
        # wav/navãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ
        if stem_dir.exists():
            wav_data, nav_data = process_stem_audio(
                stem_dir,
                ["drums", "bass", "vocals", "other"]
            )
        else:
            logger.warning(f"Stem directory not found: {stem_dir}")
            # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            wav_data = nav_data = {
                "drum": {"low": [128] * 5000, "mid": [128] * 5000, "high": [128] * 5000},
                "bass": {"low": [128] * 5000, "mid": [128] * 5000, "high": [128] * 5000},
                "vocal": {"low": [128] * 5000, "mid": [128] * 5000, "high": [128] * 5000},
                "other": {"low": [128] * 5000, "mid": [128] * 5000, "high": [128] * 5000}
            }
        
        # ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°
        data["wav"] = wav_data
        data["nav"] = nav_data
        
        # inferenceãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ä¿®æ­£
        if "inferences" in data:
            if "segments" in data["inferences"]:
                data["inferences"]["segments"] = convert_segments_format(data["inferences"]["segments"])
            
            # beats/downbeatsãŒç©ºã®å ´åˆã€ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
            if not data["inferences"].get("beats"):
                # BPMã‹ã‚‰æ¨å®šï¼ˆä¾‹ï¼š120BPMã®å ´åˆï¼‰
                bpm = data.get("scores", {}).get("beat", {}).get("bpm", 120)
                duration = data.get("duration", 240)
                beat_interval = 60.0 / bpm
                data["inferences"]["beats"] = list(np.arange(0, duration, beat_interval))
            
            if not data["inferences"].get("downbeats"):
                # 4æ‹å­ã¨ä»®å®š
                beats = data["inferences"]["beats"]
                data["inferences"]["downbeats"] = beats[::4] if beats else []
        
        # truthsãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ä¿®æ­£
        if "truths" in data:
            if "segments" in data["truths"]:
                data["truths"]["segments"] = convert_segments_format(data["truths"]["segments"])
        
        # scoresãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã¨ä¿®æ­£
        if "scores" not in data:
            data["scores"] = {
                "beat": {"f1": 1.0},
                "downbeat": {"f1": 1.0},
                "segment": {
                    "F-measure@0.5": 1.0,
                    "Pairwise F-measure": 1.0
                }
            }
        
        # å‡ºåŠ›ãƒ‘ã‚¹ã®æ±ºå®š
        if output_json_path is None:
            output_json_path = input_json_path
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(output_json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Saved converted JSON: {output_json_path}")
        return True
        
    except Exception as e:
        logger.error(f"Error converting JSON: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸµ éŸ³æ¥½åˆ†æJSONå¤‰æ›ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    # å¤‰æ›å¯¾è±¡ã®JSONãƒ•ã‚¡ã‚¤ãƒ«
    json_file = Path("music_analysis/results/0461_103additionalmemory.json")
    
    if not json_file.exists():
        # å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        original_json = Path("ui/static/struct/0461_103additionalmemory.json")
        if original_json.exists():
            import shutil
            shutil.copy(original_json, json_file)
            print(f"ğŸ“‹ JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼: {json_file}")
    
    if json_file.exists():
        print(f"\nğŸ“ å¤‰æ›å¯¾è±¡: {json_file}")
        
        # steméŸ³æºã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        stem_dir = Path("music_analysis/demix/htdemucs/1-03 Additional Memory")
        
        if stem_dir.exists():
            print(f"ğŸ¼ SteméŸ³æºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {stem_dir}")
        else:
            print(f"âš ï¸  SteméŸ³æºãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {stem_dir}")
        
        # å¤‰æ›å®Ÿè¡Œ
        print("\nğŸ”„ å¤‰æ›é–‹å§‹...")
        success = convert_json_to_ui_format(json_file, stem_dir)
        
        if success:
            print("âœ… å¤‰æ›æˆåŠŸï¼")
            
            # UIãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼
            ui_json = Path("ui/static/struct/0461_103additionalmemory.json")
            import shutil
            shutil.copy(json_file, ui_json)
            print(f"ğŸ“‹ UIãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼: {ui_json}")
        else:
            print("âŒ å¤‰æ›å¤±æ•—")
    else:
        print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {json_file}")
    
    print("\n" + "=" * 60)
    print("å®Œäº†")

if __name__ == "__main__":
    main()
